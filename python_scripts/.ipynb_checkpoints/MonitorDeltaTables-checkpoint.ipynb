{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e6f45-3b25-4f33-bf3f-87d6e62c684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b65662-8e2b-41e8-967f-b443d26feb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"SIESTA read delta Tables\")\n",
    "conf.setMaster(\"local[1]\")\n",
    "conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
    "conf.set(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "conf.set(\"spark.sql.parquet.filterPushdown\", \"true\")\n",
    "conf.set(\"spark.jars.packages\",\"io.delta:delta-core_2.12:2.4.0,org.apache.hadoop:hadoop-aws:3.3.1\")\n",
    "conf.set(\"spark.sql.extensions\",\"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog\",\"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "#conf.set(\"spark.hadoop.fs.s3a.access.key\",\"minioadmin\")\n",
    "#conf.set(\"spark.hadoop.fs.s3a.secret.key\",\"minioadmin\")\n",
    "#conf.set(\"spark.hadoop.fs.s3a.endpoint\",\"http://anaconda.csd.auth.gr:9000\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Configure S3 connection\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://anaconda.csd.auth.gr:9000\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"minioadmin\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"minioadmin\")\n",
    "#spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.connection.timeout\", \"600000\")\n",
    "#spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.connection.ssl.enabled\", \"true\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.bucket.create.enabled\", \"true\")\n",
    "\n",
    "# Read data from Delta table\n",
    "#delta_table = spark.read.format(\"delta\").load(\"s3a://siesta-test/testing/seq/\")\n",
    "#delta_table.show()\n",
    "spark.read.format(\"delta\").load(\"s3a://siesta-test/testing/seq/\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7b00e-7ec7-4e88-8fd2-29e3c5afcbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2feca5-6103-4d9f-a0ff-1ea40c08087f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
